基于硅基流动API的CoT提示优化实验
学号	姓名
3220103450	姜雨童
1.Project Introduction
1-1选题
提示微调（Prompt Tuning）是自然语言处理中的创新方法，通过设计特定输入模板或可学习嵌入向量，引导预训练语言模型适配下游任务。
本次实验承接上个实验，聚焦于思维链（Chain-of-Thought, CoT）推理场景中的提示优化，探索如何通过改进提示设计提升模型推理性能。
1-2工作简介
实验基于硅基流动API平台，使用Qwen/QwQ-32B大语言模型，在GSM8K（数学推理）和CommonsenseQA（常识问答）两个数据集上，对比传统CoT提示与优化后的"答案前置"提示方法，评估不同提示策略对模型推理性能的影响。
1-3开发环境及系统运行要求
- 软件环境：Python 3.9，主要依赖库：openai, pandas, re, httpx, tqdm
- API平台：硅基流动API（SIGFLOW）
- 硬件环境：通过API调用云端Qwen/QwQ-32B模型资源
- 数据集：GSM8K（数学问题集）、CommonsenseQA（常识问答集）
2.Technical Details
2-1 理论知识
思维链（CoT）推理：通过引导模型生成中间推理步骤，提升复杂问题的解决能力。核心思想是将问题分解为多步推理过程，模拟人类解题思维。

答案前置提示优化：在传统CoT基础上，要求模型将最终答案放置在响应开头并用特定格式标记（如[答案]）。这种方法：
（1）提高答案提取的准确性和效率；
（2）减少模型在答案后附加无关解释导致的干扰；
（3）增强模型输出的结构化程度等。
2-2 具体算法
CoT的核心在于两阶段提示设计，因此实验采用两步推理法来对比“传统CoT”和“答案前置”在其中的推理准确性（实际实验中分成version1/2两版代码）:

而CoT推理针对不同类型的问题存在不同的算法：
2-2-1 算数问题推理
在算术问题中，CoT技术尤其擅长处理多步计算任务。以GSM8K数据集中的典型问题为例：
问题：一个园丁有24朵花，他平均分给4个孩子，每个孩子得到多少朵花？
传统方法可能直接输出答案"6"，而CoT推理则展示完整过程：
- 问题解析：识别关键数字（24朵花，4个孩子）；
- 操作确定：确认需使用除法运算；
- 计算执行：24 ÷ 4 = 6；
- 答案生成：每个孩子得到6朵花。
这种分步推理不仅提高准确性（实验显示提升3-5%），还能暴露潜在错误。例如当模型错误地先做减法再做乘法（24-4=20, 20×3=60），我们能清晰定位到运算顺序误解。
2-2-2 常识问题推理
对于CommonsenseQA等常识推理任务，CoT技术通过显式连接背景知识与问题语境来提升表现：
问题：下雨时应该带什么出门？选项：A.雨伞 B.太阳镜 C.扇子
CoT推理过程：
- 情境分析：识别"下雨"的核心特征（水从天空落下）
- 功能映射：雨伞->防雨，太阳镜->防晒，扇子->降温
- 逻辑排除：排除与情境不匹配的选项（B、C）
- 答案确定：选择最符合情境的A
这种结构化推理有效解决了常识任务中的歧义问题，提高了回答准确率。
2-3 技术细节
2-3-1基础库函数
- OpenAI 客户端库：提供与硅基流动API交互的接口

- Pandas 数据处理库：高效加载和处理数据集

- 正则表达式库 (re)：实现文本模式匹配与答案提取

2-3-2核心代码实现
答案前置提示模板：

答案提取逻辑优化：


其余重要自定义函数：
- CoT 推理函数：cot_inference()：执行两阶段思维链推理
- 答案提取函数：extract_answer()：从模型响应中精确提取答案
- 数据集评估函数：evaluate_dataset()：端到端评估模型在数据集上的表现
3.Experiment Results
3-1 实验过程
3-1-1传统CoT（version1.py）
运行代码，成功连接API后开始推理并打印输出信息：

中途输出针对GSM8K的推理准确度（由于api调用频繁导致的限制等，这里推理准确度非常低）：

开始推理常识性问题（这里只采样了5个样本作为程序正确性的测试）：

最后输出实验准确性总结（同理，这里只采样了一个数学计算问题，因此这里给出的准确性不正确）：

3-1-2答案前置（version2.py）
由于使用的qwen是中文大模型，这一版代码将提示词全部改为中文，并做出了答案以特定格式前置的要求。运行代码：


可以直观感受到模型推理的准确性提高了很多，针对常识问题的推理也是一样：

3-1-3结果对比
调整输出提示信息格式后，分别对两版代码采样100个问题（数学问题50个，常识问题50个），结果如下：

（左图version1-传统CoT；右图version2-答案前置）
3-2结果分析
根据实验结果，不加任何修改的CoT推理准确率较低；而通过答案前置等方式能够有效提高推理准确率。
通过过程输出的提示信息，推理准确度较低的原因可能有以下几点：
1.API调用频繁、网络/API连接不稳定等原因导致的API调用失败，在经过多次尝试且超时后，直接略过该题目，导致该题推理出错：


2.读取token的限制：token数过小时，程序不能获得大语言模型完整的输出，而传统CoT在推理数学问题时选择提取token中最后一个数字作为答案，因此非完整的输出直接导致了提取到的答案错误，即使大语言模型给出了正确的答案：


3.题库自身题目可能存在一定问题，例如下面这题根据题干只能排除CDE三个选项，并不能真正判断答案是A还是B（二者皆有道理）。根据输出token来看，大语言模型也在A和B选项中抉择，最终错误判断答案为B：

References:
1 API调用接口：创建文本对话请求 - SiliconFlow
2 一文读懂：思维链 CoT（Chain of Thought）

附录-关于报告在ddl后上交的说明：
最开始仍旧试图使用华为云的mindspore平台，但是代金券不够了，因此在五月底的时候向助教申请了新的代金券。由于此前下发代金券的时候平台有短信提示，因此在没收到短信的时候一直没想到登录平台查看代金券，后来时间比较久了才登录平台查看，最后发现这次发的短信被归到垃圾短信里拦截了，因此我发现代金券下发的时间比它实际下发的时间迟了很多。
而在mindspore运行的时候发现推理速度非常慢，而且一不小心中断了就得重新开始，耗时过久，因此转而选择了调用“硅基流动”的api。而实验过程中又发现api调用过于频繁时会被锁定，因此延长了代码中api调用间隔时间，最终导致实验耗时较久，拖延ddl较久。